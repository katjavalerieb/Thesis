{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f890d4d-ea0e-4077-a4f0-5b1005e544c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import functional as TF\n",
    "import torch.nn.init as init\n",
    "from torchsummary import summary\n",
    "\n",
    "# Image preprocessing\n",
    "from skimage.transform import resize\n",
    "\n",
    "# Model and training utilities\n",
    "import segmentation_models_pytorch as smp\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Setup\n",
    "import logging\n",
    "\n",
    "import pickle \n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "dir = Path(\"/work3/kvabo/PKGCTORG/newCT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551a16a6-b836-4278-9a01-e3a7e00d3fb7",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc8dcbec-ee92-4f46-9d62-8b3014814742",
   "metadata": {},
   "outputs": [],
   "source": [
    "maeLoss = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7716e49c-30ae-471d-9389-9a0b698ce483",
   "metadata": {},
   "source": [
    "# QC U-Net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "521092d1-5eb1-48dc-8494-d0ec9b88c2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        self.conv = ConvBlock(in_channels, out_channels)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_conv = self.conv(x)\n",
    "        x_pool = self.pool(x_conv)\n",
    "        return x_pool, x_conv\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels, skip_channels, out_channels):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        self.up = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n",
    "        self.block = nn.Sequential(\n",
    "            nn.BatchNorm2d(out_channels + skip_channels),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv2d(out_channels + skip_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x, skip):\n",
    "        x = self.up(x)\n",
    "        x = torch.cat((skip, x), dim=1)\n",
    "        return self.block(x)\n",
    "\n",
    "class QCUNet(nn.Module):\n",
    "    def __init__(self, in_channels=2):\n",
    "        super(QCUNet, self).__init__()\n",
    "        self.enc1 = EncoderBlock(in_channels, 40)\n",
    "        self.enc2 = EncoderBlock(40, 40)\n",
    "        self.enc3 = EncoderBlock(40, 80)\n",
    "        self.enc4 = EncoderBlock(80, 160)\n",
    "        self.enc5 = EncoderBlock(160, 320)\n",
    "\n",
    "        self.bottleneck = ConvBlock(320, 640)\n",
    "\n",
    "        self.dec5 = DecoderBlock(640, 320, 320)\n",
    "        self.dec4 = DecoderBlock(320, 160, 160)\n",
    "        self.dec3 = DecoderBlock(160, 80, 80)\n",
    "        self.dec2 = DecoderBlock(80, 40, 40)\n",
    "        self.dec1 = DecoderBlock(40, 40, 40)\n",
    "\n",
    "        self.output_conv = nn.Conv2d(40, 1, kernel_size=1)\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))  # Outputs shape (B, 1, 1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1_pool, x1 = self.enc1(x)\n",
    "        x2_pool, x2 = self.enc2(x1_pool)\n",
    "        x3_pool, x3 = self.enc3(x2_pool)\n",
    "        x4_pool, x4 = self.enc4(x3_pool)\n",
    "        x5_pool, x5 = self.enc5(x4_pool)\n",
    "\n",
    "        x = self.bottleneck(x5_pool)\n",
    "\n",
    "        x = self.dec5(x, x5)\n",
    "        x = self.dec4(x, x4)\n",
    "        x = self.dec3(x, x3)\n",
    "        x = self.dec2(x, x2)\n",
    "        x = self.dec1(x, x1)\n",
    "\n",
    "        x = self.output_conv(x)                    # (B, 1, H, W)\n",
    "        x = self.global_avg_pool(x)                # (B, 1, 1, 1)\n",
    "        return x.view(x.size(0), -1)               # Flatten to shape (B, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d6df9e4-b76a-4d05-9a1c-7ee688dae46f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      2\u001b[0m summary(model, (\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "summary(model, (2, 256, 256))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96df53a2-a5d5-4f9d-955d-d6df4238f274",
   "metadata": {},
   "source": [
    "# Try overfitting to check that it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "416080ab-9a2d-48c0-a70f-3c30a94fe098",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "from pathlib import Path\n",
    "\n",
    "class QCDataset(Dataset):\n",
    "    def __init__(self, qc_dir, ct_dir):\n",
    "        self.qc_dir = Path(qc_dir)\n",
    "        self.ct_dir = Path(ct_dir)\n",
    "\n",
    "        # Load CSV containing metadata (case, slice, dsc)\n",
    "        self.data = pd.read_csv(self.qc_dir / \"results.csv\")  # <--- FIXED: 'self.qcData' â†’ 'self.data'\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        case_number = int(row['case'])\n",
    "        slice_idx = int(row['slice'])\n",
    "        dsc = float(row['dsc'])\n",
    "\n",
    "        # Load predicted segmentation\n",
    "        seg_path = self.qc_dir / f\"{case_number}_slice_{slice_idx}_pred.npy\"\n",
    "        seg = np.load(seg_path).astype(np.float32)\n",
    "\n",
    "        # Load CT slice\n",
    "        ct_path = self.ct_dir / f\"volume-{case_number}.npy\"\n",
    "        ct = np.load(ct_path)[:, :, slice_idx]  # shape: [H, W]\n",
    "        ct_image = Image.fromarray(ct).convert(\"F\")\n",
    "        ct_image = TF.resize(ct_image, (256, 256))\n",
    "        ct_resized = np.array(ct_image, dtype=np.float32)\n",
    "\n",
    "        # Stack CT and prediction\n",
    "        X = np.stack([ct_resized, seg], axis=0)  # shape: [2, 256, 256]\n",
    "        X_tensor = torch.tensor(X)\n",
    "\n",
    "        return X_tensor, torch.tensor(dsc, dtype=torch.float32), case_number, slice_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198a56e7-b481-4564-b7ac-24cab0b1bab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTOrganSegDataset(Dataset):\n",
    "    def __init__(self, case_numbers, dir, filteredData=Path(\"kidneySlices.pkl\")):\n",
    "        self.case_numbers = case_numbers\n",
    "        self.data_dir = Path(dir)\n",
    "        self.resize_size = (256, 256)\n",
    "\n",
    "        # Load precomputed slice data\n",
    "        with open(filteredData, 'rb') as f:\n",
    "            all_slice_data = pickle.load(f)\n",
    "\n",
    "        # Keep only slices for relevant cases\n",
    "        self.slice_data = [\n",
    "            (case_number, slice_idx)\n",
    "            for (case_number, slice_idx) in all_slice_data\n",
    "            if case_number in self.case_numbers\n",
    "        ]\n",
    "\n",
    "        # Preload volume and label paths\n",
    "        self.volumePaths = {\n",
    "            case_number: self.data_dir / f\"volume-{case_number}.npy\"\n",
    "            for case_number in self.case_numbers\n",
    "        }\n",
    "        self.labelPaths = {\n",
    "            case_number: self.data_dir / f\"labels-{case_number}.npy\"\n",
    "            for case_number in self.case_numbers\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.slice_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        case_number, slice_idx = self.slice_data[idx]\n",
    "        volume = np.load(self.volumePaths[case_number])\n",
    "        label = np.load(self.labelPaths[case_number])\n",
    "\n",
    "        volume_slice = volume[:, :, slice_idx]\n",
    "        label_slice = label[:, :, slice_idx]\n",
    "\n",
    "        # Resize CT slice\n",
    "        volume_pil = Image.fromarray(volume_slice).convert(\"F\")\n",
    "        volume_resized = TF.resize(volume_pil, self.resize_size)\n",
    "        volume_array = np.array(volume_resized, dtype=np.float32)\n",
    "\n",
    "        # Determine which class to segment\n",
    "        target_class = 4\n",
    "        binary_mask = (label_slice == target_class).astype(np.uint8)\n",
    "\n",
    "        # Resize mask\n",
    "        mask_pil = Image.fromarray(binary_mask * 255)\n",
    "        mask_resized = TF.resize(mask_pil, self.resize_size)\n",
    "        mask_array = np.array(mask_resized) / 255.0\n",
    "\n",
    "        # Stack input and mask\n",
    "        X = np.stack([volume_array, mask_array], axis=0).astype(np.float32)\n",
    "\n",
    "        return torch.tensor(X), case_number, slice_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94569bd6-4edd-440a-88e9-c907e7fafdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "qc_dir = Path( \"/work3/kvabo/predictions/qcLiverDsc0.7\")\n",
    "df = pd.read_csv(Path( \"/work3/kvabo/predictions/qcLiverDsc0.7/results.csv\"))\n",
    "case0 = df[(df[\"case\"] == 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc21bf38-8d1b-45cc-b27e-3b7f676c0139",
   "metadata": {},
   "source": [
    "### Calculate the MVSF \n",
    "The MVSF takes values in the range $[-2, 2]$. Since our neural network uses a sigmoid activation at the output, we normalize the MVSF to the interval $[0, 1]$ during training. Specifically, we store the normalized value in the CSV file as:\n",
    "\n",
    "$\\text{MVSF}_{\\text{normalized}} = \\frac{\\text{MVSF} + 2}{4}$\n",
    "\n",
    "This makes the target compatible with the sigmoid output and simplifies data loading. When the original MVSF value is needed (e.g., for estimating the 3D DSC), it can be recovered from the predicted normalized value using:\n",
    "\n",
    "$\n",
    "\\text{MVSF} = 4 \\cdot \\text{pred} - 2\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "05ef81fa-7c86-4379-aac4-5f8ca2bb1e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case</th>\n",
       "      <th>slice</th>\n",
       "      <th>model</th>\n",
       "      <th>dsc</th>\n",
       "      <th>prediction_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>qcLiverDsc0.7</td>\n",
       "      <td>0.31842</td>\n",
       "      <td>0_slice_45_pred.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>qcLiverDsc0.7</td>\n",
       "      <td>0.57035</td>\n",
       "      <td>0_slice_46_pred.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>qcLiverDsc0.7</td>\n",
       "      <td>0.52927</td>\n",
       "      <td>0_slice_47_pred.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>qcLiverDsc0.7</td>\n",
       "      <td>0.59340</td>\n",
       "      <td>0_slice_48_pred.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>qcLiverDsc0.7</td>\n",
       "      <td>0.69461</td>\n",
       "      <td>0_slice_49_pred.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>qcLiverDsc0.7</td>\n",
       "      <td>0.75177</td>\n",
       "      <td>0_slice_50_pred.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>qcLiverDsc0.7</td>\n",
       "      <td>0.78395</td>\n",
       "      <td>0_slice_51_pred.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>qcLiverDsc0.7</td>\n",
       "      <td>0.84579</td>\n",
       "      <td>0_slice_52_pred.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>qcLiverDsc0.7</td>\n",
       "      <td>0.86940</td>\n",
       "      <td>0_slice_53_pred.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>qcLiverDsc0.7</td>\n",
       "      <td>0.84434</td>\n",
       "      <td>0_slice_54_pred.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>qcLiverDsc0.7</td>\n",
       "      <td>0.83760</td>\n",
       "      <td>0_slice_55_pred.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>qcLiverDsc0.7</td>\n",
       "      <td>0.83035</td>\n",
       "      <td>0_slice_56_pred.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>qcLiverDsc0.7</td>\n",
       "      <td>0.83715</td>\n",
       "      <td>0_slice_57_pred.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>qcLiverDsc0.7</td>\n",
       "      <td>0.79014</td>\n",
       "      <td>0_slice_58_pred.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>qcLiverDsc0.7</td>\n",
       "      <td>0.83678</td>\n",
       "      <td>0_slice_59_pred.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>qcLiverDsc0.7</td>\n",
       "      <td>0.83428</td>\n",
       "      <td>0_slice_60_pred.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>qcLiverDsc0.7</td>\n",
       "      <td>0.82986</td>\n",
       "      <td>0_slice_61_pred.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>qcLiverDsc0.7</td>\n",
       "      <td>0.81968</td>\n",
       "      <td>0_slice_62_pred.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>qcLiverDsc0.7</td>\n",
       "      <td>0.82721</td>\n",
       "      <td>0_slice_63_pred.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>qcLiverDsc0.7</td>\n",
       "      <td>0.80787</td>\n",
       "      <td>0_slice_64_pred.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>qcLiverDsc0.7</td>\n",
       "      <td>0.77742</td>\n",
       "      <td>0_slice_65_pred.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>qcLiverDsc0.7</td>\n",
       "      <td>0.77140</td>\n",
       "      <td>0_slice_66_pred.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>qcLiverDsc0.7</td>\n",
       "      <td>0.79587</td>\n",
       "      <td>0_slice_67_pred.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>qcLiverDsc0.7</td>\n",
       "      <td>0.80290</td>\n",
       "      <td>0_slice_68_pred.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>qcLiverDsc0.7</td>\n",
       "      <td>0.75268</td>\n",
       "      <td>0_slice_69_pred.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>qcLiverDsc0.7</td>\n",
       "      <td>0.68923</td>\n",
       "      <td>0_slice_70_pred.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>qcLiverDsc0.7</td>\n",
       "      <td>0.54074</td>\n",
       "      <td>0_slice_71_pred.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>qcLiverDsc0.7</td>\n",
       "      <td>0.45592</td>\n",
       "      <td>0_slice_72_pred.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>qcLiverDsc0.7</td>\n",
       "      <td>0.20753</td>\n",
       "      <td>0_slice_73_pred.npy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    case  slice          model      dsc      prediction_file\n",
       "0      0     45  qcLiverDsc0.7  0.31842  0_slice_45_pred.npy\n",
       "1      0     46  qcLiverDsc0.7  0.57035  0_slice_46_pred.npy\n",
       "2      0     47  qcLiverDsc0.7  0.52927  0_slice_47_pred.npy\n",
       "3      0     48  qcLiverDsc0.7  0.59340  0_slice_48_pred.npy\n",
       "4      0     49  qcLiverDsc0.7  0.69461  0_slice_49_pred.npy\n",
       "5      0     50  qcLiverDsc0.7  0.75177  0_slice_50_pred.npy\n",
       "6      0     51  qcLiverDsc0.7  0.78395  0_slice_51_pred.npy\n",
       "7      0     52  qcLiverDsc0.7  0.84579  0_slice_52_pred.npy\n",
       "8      0     53  qcLiverDsc0.7  0.86940  0_slice_53_pred.npy\n",
       "9      0     54  qcLiverDsc0.7  0.84434  0_slice_54_pred.npy\n",
       "10     0     55  qcLiverDsc0.7  0.83760  0_slice_55_pred.npy\n",
       "11     0     56  qcLiverDsc0.7  0.83035  0_slice_56_pred.npy\n",
       "12     0     57  qcLiverDsc0.7  0.83715  0_slice_57_pred.npy\n",
       "13     0     58  qcLiverDsc0.7  0.79014  0_slice_58_pred.npy\n",
       "14     0     59  qcLiverDsc0.7  0.83678  0_slice_59_pred.npy\n",
       "15     0     60  qcLiverDsc0.7  0.83428  0_slice_60_pred.npy\n",
       "16     0     61  qcLiverDsc0.7  0.82986  0_slice_61_pred.npy\n",
       "17     0     62  qcLiverDsc0.7  0.81968  0_slice_62_pred.npy\n",
       "18     0     63  qcLiverDsc0.7  0.82721  0_slice_63_pred.npy\n",
       "19     0     64  qcLiverDsc0.7  0.80787  0_slice_64_pred.npy\n",
       "20     0     65  qcLiverDsc0.7  0.77742  0_slice_65_pred.npy\n",
       "21     0     66  qcLiverDsc0.7  0.77140  0_slice_66_pred.npy\n",
       "22     0     67  qcLiverDsc0.7  0.79587  0_slice_67_pred.npy\n",
       "23     0     68  qcLiverDsc0.7  0.80290  0_slice_68_pred.npy\n",
       "24     0     69  qcLiverDsc0.7  0.75268  0_slice_69_pred.npy\n",
       "25     0     70  qcLiverDsc0.7  0.68923  0_slice_70_pred.npy\n",
       "26     0     71  qcLiverDsc0.7  0.54074  0_slice_71_pred.npy\n",
       "27     0     72  qcLiverDsc0.7  0.45592  0_slice_72_pred.npy\n",
       "28     0     73  qcLiverDsc0.7  0.20753  0_slice_73_pred.npy"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "894a8678-c350-4035-9c75-6d9d66a25b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case</th>\n",
       "      <th>slice</th>\n",
       "      <th>model</th>\n",
       "      <th>dsc</th>\n",
       "      <th>prediction_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>qcLiverDsc0.7</td>\n",
       "      <td>0.31842</td>\n",
       "      <td>0_slice_45_pred.npy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   case  slice          model      dsc      prediction_file\n",
       "0     0     45  qcLiverDsc0.7  0.31842  0_slice_45_pred.npy"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case0[case0['slice'] == 45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abe173ba-ae90-49c0-aa10-b576c4f0b112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones((3,3,3)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99ad4139-098b-47a7-8af1-2cf8a33ba521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = np.ones((3,3)).flatten()\n",
    "Z = np.zeros((3,3)).flatten()\n",
    "Z[2] = 1\n",
    "\n",
    "np.sum(Y*Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "df241cd9-76e9-48ff-90c1-826d9ee11bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DSC(Y, Z):\n",
    "    # Y nSlicesx256x256\n",
    "    Y = Y.flatten()\n",
    "    Z = Z.flatten()\n",
    "    # numerator \n",
    "    num = 2*np.sum(Y*Z)\n",
    "\n",
    "    # denominator \n",
    "    denom = np.sum(Y) + np.sum(Z)\n",
    "\n",
    "    return num/denom\n",
    "    \n",
    "    \n",
    "\n",
    "def MVSF(Y,Z):\n",
    "    Y = np.sum(Y.flatten())\n",
    "    Z = np.sum(Z.flatten())\n",
    "\n",
    "    # numerator\n",
    "    num = 2*(Y - Z)\n",
    "\n",
    "    # denominator\n",
    "    denom = Y + Z\n",
    "\n",
    "    return num/denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e7d9f377-0c6e-4920-814f-bd1204d22515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gtSeg0.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3a2d0e46-ec58-4f21-aa13-e3c3a4f29f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gtSeg0 = np.load(dir / f\"labels-{0}.npy\").astype(np.uint8)\n",
    "target_class = 1\n",
    "ct_path = dir / f\"volume-{0}.npy\"\n",
    "Z = []\n",
    "YHat = []\n",
    "YZHat = []\n",
    "for slice in case0['slice']:\n",
    "    gtSegslice = gtSeg0[:, :, slice]\n",
    "    binary_mask = (gtSegslice == target_class).astype(np.uint8)\n",
    "    \n",
    "    # Resize mask\n",
    "    mask_pil = Image.fromarray(binary_mask * 255)\n",
    "    mask_resized = TF.resize(mask_pil, (256, 256))\n",
    "    mask_array = np.array(mask_resized) / 255.0\n",
    "\n",
    "    dsc = case0[case0['slice'] == slice]['dsc']\n",
    "\n",
    "    # Load predicted segmentation\n",
    "    seg_path = qc_dir / f\"{0}_slice_{slice}_pred.npy\"\n",
    "    seg = np.load(seg_path).astype(np.float32)\n",
    "\n",
    "    # Load CT slice\n",
    "    \n",
    "    ct = np.load(ct_path)[:, :, slice]  # shape: [H, W]\n",
    "    ct_image = Image.fromarray(ct).convert(\"F\")\n",
    "    ct_image = TF.resize(ct_image, (256, 256))\n",
    "    ct_resized = np.array(ct_image, dtype=np.float32)\n",
    "\n",
    "    dice = DSC(mask_array,seg)\n",
    "    mvsf = MVSF(mask_array,seg)\n",
    "    z = np.sum(seg.flatten())\n",
    "    yHat = z*(2+mvsf)/(2-mvsf)\n",
    "    yzHat = 0.5*dsc*(yHat + z)\n",
    "\n",
    "    Z.append(z)\n",
    "    YHat.append(yHat)\n",
    "    YZHat.append(yzHat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7238d1d4-95d6-46d0-bc9f-707c5b38b694",
   "metadata": {},
   "outputs": [],
   "source": [
    "qc_dir = Path( \"/work3/kvabo/predictions/qcKidneyDsc1.0\")\n",
    "targetClass = 4\n",
    "df = pd.read_csv(qc_dir /\"results.csv\")\n",
    "case0 = df[(df[\"case\"] == 0)]\n",
    "gtSeg0 = np.load(dir / f\"labels-{0}.npy\").astype(np.uint8)\n",
    "\n",
    "ct_path = dir / f\"volume-{0}.npy\"\n",
    "Z = []\n",
    "YHat = []\n",
    "YZHat = []\n",
    "\n",
    "n_total_slices = gtSeg0.shape[2]\n",
    "\n",
    "# Preallocate volume of zeros\n",
    "pred = np.zeros((512, 512, n_total_slices), dtype=np.float32)\n",
    "\n",
    "for slice in case0['slice']:\n",
    " \n",
    "    # Load predicted segmentation\n",
    "    seg_path = qc_dir / f\"{0}_slice_{slice}_pred.npy\"\n",
    "    seg = np.load(seg_path).astype(np.float32)\n",
    "\n",
    "    # Resize to (512, 512)\n",
    "    seg_image = Image.fromarray((seg * 255).astype(np.uint8))  # convert to image\n",
    "    seg_resized = TF.resize(seg_image, size=(512, 512), interpolation=TF.InterpolationMode.NEAREST)\n",
    "\n",
    "    # Convert back to NumPy and binarize if needed\n",
    "    seg_resized_array = np.array(seg_resized).astype(np.uint8) // 255  # back to [0, 1]\n",
    "    # Set class label\n",
    "    pred[:, :, slice] = seg_resized_array * target_class\n",
    "    #pred[:, :,slice] = seg*targetClass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7ec0c2f7-2504-4066-9e92-ad29267afa43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     34\n",
       "1     35\n",
       "2     36\n",
       "3     37\n",
       "4     38\n",
       "5     39\n",
       "6     40\n",
       "7     41\n",
       "8     42\n",
       "9     43\n",
       "10    44\n",
       "11    45\n",
       "12    46\n",
       "13    47\n",
       "14    48\n",
       "15    49\n",
       "16    50\n",
       "17    51\n",
       "18    52\n",
       "19    53\n",
       "20    54\n",
       "21    55\n",
       "22    56\n",
       "23    57\n",
       "Name: slice, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kidneySlices[\"slice\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "00a8f62f-bf19-4f54-ae8c-0354a692d254",
   "metadata": {},
   "outputs": [],
   "source": [
    "nCase = 0\n",
    "\n",
    "qcDirKidney = Path( \"/work3/kvabo/predictions/qcKidneyDsc0.4\")\n",
    "qcDirLiver = Path( \"/work3/kvabo/predictions/qcLiverDsc0.4\")\n",
    "\n",
    "dfKidney = pd.read_csv(qcDirKidney /\"results.csv\")\n",
    "dfLiver = pd.read_csv(qcDirLiver /\"results.csv\")\n",
    "\n",
    "kidneySlices = dfKidney[(dfKidney[\"case\"] == nCase )]\n",
    "liverSlices = dfLiver[(dfLiver[\"case\"] == nCase )]\n",
    "\n",
    "\n",
    "\n",
    "gtSeg0 = np.load(dir / f\"labels-{0}.npy\").astype(np.uint8)\n",
    "\n",
    "ct_path = dir / f\"volume-{0}.npy\"\n",
    "Z = []\n",
    "YHat = []\n",
    "YZHat = []\n",
    "\n",
    "n_total_slices = gtSeg0.shape[2]\n",
    "\n",
    "# Preallocate volume of zeros\n",
    "pred = np.zeros((512, 512, n_total_slices), dtype=np.float32)\n",
    "\n",
    "for slice in range(n_total_slices):\n",
    "    kidneyMask = np.zeros((512, 512), dtype=np.uint8)\n",
    "    liverMask = np.zeros((512, 512), dtype=np.uint8)\n",
    "\n",
    "    if slice in kidneySlices[\"slice\"].values:\n",
    "        # Load predicted segmentation\n",
    "        segPathKidney = qcDirKidney / f\"{0}_slice_{slice}_pred.npy\"\n",
    "        segKidney = np.load(segPathKidney).astype(np.float32)\n",
    "    \n",
    "        # Resize to (512, 512)\n",
    "        segKidney = Image.fromarray((segKidney * 255).astype(np.uint8))  # convert to image\n",
    "        segKidney = TF.resize(segKidney, size=(512, 512), interpolation=TF.InterpolationMode.NEAREST)\n",
    "    \n",
    "        # Convert back to NumPy and binarize if needed\n",
    "        segKidney = np.array(segKidney).astype(np.uint8) // 255  # back to [0, 1]\n",
    "        # Set class label\n",
    "        kidneyMask = segKidney \n",
    "\n",
    "    if slice in liverSlices[\"slice\"].values:\n",
    "        # Load predicted segmentation\n",
    "        segPathLiver = qcDirLiver / f\"{0}_slice_{slice}_pred.npy\"\n",
    "        segLiver = np.load(segPathLiver).astype(np.float32)\n",
    "    \n",
    "        # Resize to (512, 512)\n",
    "        segLiver= Image.fromarray((segLiver * 255).astype(np.uint8))  # convert to image\n",
    "        segLiver = TF.resize(segLiver, size=(512, 512), interpolation=TF.InterpolationMode.NEAREST)\n",
    "    \n",
    "        # Convert back to NumPy and binarize if needed\n",
    "        segLiver = np.array(segLiver).astype(np.uint8) // 255  # back to [0, 1]\n",
    "        # Set class label\n",
    "        liverMask = segLiver\n",
    "    # Zero out overlapping pixels\n",
    "    overlap = (kidneyMask == 1) & (liverMask == 1)\n",
    "    kidneyMask[overlap] = 0\n",
    "    liverMask[overlap] = 0\n",
    "\n",
    "    # Assign class labels\n",
    "    pred[:, :, slice] = kidneyMask * 4 + liverMask  # kidney=4, liver=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e94db5fd-14b0-44ed-9d90-dd5810ae4804",
   "metadata": {},
   "outputs": [],
   "source": [
    "nii_path = \"/work3/kvabo/PKGCTORG/CTORG/OrganSegmentations/labels-0.nii.gz\"\n",
    "nii = nib.load(nii_path)\n",
    "orig_affine = nii.affine\n",
    "\n",
    "# Save resized volume with the original affine\n",
    "nib.save(nib.Nifti1Image(pred, affine=orig_affine), \"pred.nii.gz\")\n",
    "#nib.save(nifti_img, f\"predicted_seg_case{0}.nii.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1bea3c23-9967-4239-8dfc-39639e8bddd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (512, 512, 75)\n",
      "Voxel spacing: (0.703125, 0.703125, 5.0)\n",
      "Affine matrix:\n",
      " [[  -0.703125     0.           0.         172.8999939]\n",
      " [   0.           0.703125     0.        -179.296875 ]\n",
      " [   0.           0.           5.        -368.       ]\n",
      " [   0.           0.           0.           1.       ]]\n",
      "Data type: int16\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "\n",
    "# Load the original NIfTI file\n",
    "nii_path = \"/work3/kvabo/PKGCTORG/CTORG/OrganSegmentations/labels-0.nii.gz\"\n",
    "nii = nib.load(nii_path)\n",
    "\n",
    "# Check the shape\n",
    "print(\"Shape:\", nii.shape)\n",
    "\n",
    "# Check the voxel spacing (pixel dimensions)\n",
    "print(\"Voxel spacing:\", nii.header.get_zooms())\n",
    "\n",
    "# Check the affine matrix (position and orientation in space)\n",
    "print(\"Affine matrix:\\n\", nii.affine)\n",
    "\n",
    "# Optional: data type\n",
    "print(\"Data type:\", nii.get_data_dtype())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0ac6cf8-92d4-4175-a449-824b81c3b6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "case_id = 0\n",
    "target_class = 1\n",
    "case0 = pd.read_csv(qc_dir / \"results.csv\")\n",
    "case0 = case0[case0['case'] == case_id]\n",
    "\n",
    "# Load full label and CT volumes\n",
    "gt_volume = np.load(dir / f\"labels-{case_id}.npy\").astype(np.uint8)\n",
    "ct_volume = np.load(dir / f\"volume-{case_id}.npy\").astype(np.float32)\n",
    "\n",
    "# Output lists\n",
    "gt_masks = []\n",
    "pred_masks = []\n",
    "ct_slices = []\n",
    "\n",
    "\n",
    "# Loop over selected slices\n",
    "for slice_idx in case0['slice']:\n",
    "    # Ground truth mask for the target class\n",
    "    gt_slice = gt_volume[:, :, slice_idx]\n",
    "    binary_mask = (gt_slice == target_class).astype(np.uint8)\n",
    "    mask_resized = TF.resize(Image.fromarray(binary_mask * 255), (256, 256))\n",
    "    mask_array = np.array(mask_resized) / 255.0  # convert to float32 mask\n",
    "    gt_masks.append(mask_array.astype(np.uint8))\n",
    "\n",
    "    # Predicted segmentation\n",
    "    seg_path = qc_dir / f\"{case_id}_slice_{slice_idx}_pred.npy\"\n",
    "    pred_mask = np.load(seg_path)\n",
    "    pred_masks.append(pred_mask)\n",
    "\n",
    "    # CT slice\n",
    "    ct_slice = ct_volume[:, :, slice_idx]\n",
    "    ct_resized = TF.resize(Image.fromarray(ct_slice).convert(\"F\"), (256, 256))\n",
    "    ct_array = np.array(ct_resized, dtype=np.float32)\n",
    "    ct_slices.append(ct_array)\n",
    "\n",
    "\n",
    "# Optional: convert to arrays\n",
    "gt_masks = np.stack(gt_masks)           # (N, 256, 256)\n",
    "pred_masks = np.stack(pred_masks)       # (N, 256, 256)\n",
    "ct_slices = np.stack(ct_slices)         # (N, 256, 256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dba2fba7-82cd-474b-8be5-2555f4a201c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7874422113779376"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsc3D(gt_masks, pred_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e936d4ac-cc11-4098-83e5-02c0a82349ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "\n",
    "# Load full dataset\n",
    "full_dataset = QCKidneyDataset(\"/work3/kvabo/predictions/qcLiverDsc0.5\", dir)\n",
    "\n",
    "# Convert to DataFrame for filtering\n",
    "full_df = full_dataset.data\n",
    "\n",
    "# Get indices for test and train based on case numbers\n",
    "test_indices = full_df.index[full_df['case'].between(1, 21)].tolist()\n",
    "train_indices = full_df.index[full_df['case'].between(22, 140)].tolist()\n",
    "\n",
    "# Create Subsets\n",
    "train_dataset = Subset(full_dataset, train_indices)\n",
    "test_dataset = Subset(full_dataset, test_indices)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 5\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=8, shuffle=True,persistent_workers=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=8, shuffle=False,persistent_workers=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9bf2935c-8686-4cbd-ad80-019f1e6e4b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0018, 0.1177, 0.2498, 0.3952, 0.5546])\n",
      "tensor([1, 1, 1, 1, 1])\n",
      "tensor([0.6424, 0.6306, 0.6282, 0.6248, 0.6197])\n",
      "tensor([1, 1, 1, 1, 1])\n",
      "tensor([0.5874, 0.5655, 0.5746, 0.4988, 0.5059])\n",
      "tensor([1, 1, 1, 1, 1])\n",
      "tensor([0.4834, 0.4766, 0.5210, 0.5493, 0.5592])\n",
      "tensor([1, 1, 1, 1, 1])\n",
      "tensor([0.5473, 0.5387, 0.5116, 0.5162, 0.5218])\n",
      "tensor([1, 1, 1, 1, 1])\n",
      "tensor([0.5726, 0.5148, 0.4717, 0.0265, 0.0098])\n",
      "tensor([1, 1, 1, 1, 2])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdsc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcase_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslice_indices\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdsc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcase_ids\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenvv3.11.7/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/myenvv3.11.7/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1327\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1328\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1331\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/myenvv3.11.7/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1294\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1290\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1293\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1294\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1295\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1296\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/myenvv3.11.7/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/appl/python/3.11.7/lib/python3.11/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[0;32m/appl/python/3.11.7/lib/python3.11/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/appl/python/3.11.7/lib/python3.11/multiprocessing/connection.py:440\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 440\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/appl/python/3.11.7/lib/python3.11/multiprocessing/connection.py:947\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    944\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    946\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 947\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    948\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    949\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m/appl/python/3.11.7/lib/python3.11/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selector\u001b[38;5;241m.\u001b[39mpoll(timeout)\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for batch_idx, (X, dsc, case_ids, slice_indices) in enumerate(test_loader):\n",
    "    print(dsc)\n",
    "    print(case_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83572d22-f873-4838-9171-9e44e956af2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3489, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3684, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2763, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2658, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2736, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1569, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2548, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2186, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2280, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1618, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2705, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2186, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2164, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1351, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2051, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0732, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0945, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3484, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1789, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1336, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1483, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1535, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1844, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1745, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2020, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1685, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2522, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0846, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0729, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1648, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0988, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1397, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2126, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1325, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1750, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0696, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1328, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3134, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1846, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1751, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1714, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1388, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1870, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1508, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m     20\u001b[0m     running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m---> 21\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdsc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcase_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslice_indices\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdsc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdsc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenvv3.11.7/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/myenvv3.11.7/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1327\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1328\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1331\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/myenvv3.11.7/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1294\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1290\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1293\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1294\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1295\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1296\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/myenvv3.11.7/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/appl/python/3.11.7/lib/python3.11/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[0;32m/appl/python/3.11.7/lib/python3.11/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/appl/python/3.11.7/lib/python3.11/multiprocessing/connection.py:440\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 440\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/appl/python/3.11.7/lib/python3.11/multiprocessing/connection.py:947\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    944\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    946\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 947\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    948\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    949\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m/appl/python/3.11.7/lib/python3.11/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selector\u001b[38;5;241m.\u001b[39mpoll(timeout)\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = QCUNet()\n",
    "\n",
    "def init_he(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "\n",
    "model.apply(init_he)\n",
    "model = model.to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(opt, step_size=20, gamma=0.7)\n",
    "\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (X, dsc, case_ids, slice_indices) in enumerate(train_loader):\n",
    "        X = X.to(device)\n",
    "        dsc = dsc.to(device)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        outputs = model(X)  # Regression: output shape [batch_size, 1]\n",
    "        pred_dsc = torch.sigmoid(outputs).squeeze()\n",
    "\n",
    "        loss = maeLoss(pred_dsc, dsc)\n",
    "        print(loss)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    scheduler.step()\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d20e3d5-5fe1-43e7-b465-bd10c32b71cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "diceLoss = smp.losses.DiceLoss(mode='binary', from_logits=False, eps=1e-7, smooth = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba7605a5-df30-4e91-831f-7ecb38481689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.ones((4,2))\n",
    "#a =np.flatten(a)\n",
    "np.sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "591c1545-8371-4155-91e3-6044cc249e11",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 1553980, 1554005, 1554029, 1554053, 1554077, 1554101, 1554125, 1554149) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[0;32m~/myenvv3.11.7/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "File \u001b[0;32m/appl/python/3.11.7/lib/python3.11/multiprocessing/queues.py:114\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll(timeout):\n\u001b[0;32m--> 114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "\u001b[0;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m     mvsf \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m(y\u001b[38;5;241m-\u001b[39mz)\u001b[38;5;241m/\u001b[39m(y\u001b[38;5;241m+\u001b[39mz)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mvsf\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (X, dsc, case_ids, slice_indices) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(dsc, case_ids, slice_indices)\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(batch_idx)\n",
      "File \u001b[0;32m~/myenvv3.11.7/lib/python3.11/site-packages/torch/utils/data/dataloader.py:435\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_iterator()\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 435\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/myenvv3.11.7/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1111\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._reset\u001b[0;34m(self, loader, first_iter)\u001b[0m\n\u001b[1;32m   1109\u001b[0m resume_iteration_cnt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_workers\n\u001b[1;32m   1110\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m resume_iteration_cnt \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1111\u001b[0m     return_idx, return_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(return_idx, _utils\u001b[38;5;241m.\u001b[39mworker\u001b[38;5;241m.\u001b[39m_ResumeIteration):\n\u001b[1;32m   1113\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m return_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/myenvv3.11.7/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1294\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1290\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1293\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1294\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1295\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1296\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/myenvv3.11.7/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1145\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1144\u001b[0m     pids_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(w\u001b[38;5;241m.\u001b[39mpid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[0;32m-> 1145\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpids_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) exited unexpectedly\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue\u001b[38;5;241m.\u001b[39mEmpty):\n\u001b[1;32m   1147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 1553980, 1554005, 1554029, 1554053, 1554077, 1554101, 1554125, 1554149) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "target_class =4\n",
    "def mvsf(pred, gt):\n",
    "    y = np.sum(gt)\n",
    "    z = np.sum(pred)\n",
    "    mvsf = 2*(y-z)/(y+z)\n",
    "    return mvsf\n",
    "\n",
    "for batch_idx, (X, dsc, case_ids, slice_indices) in enumerate(test_loader):\n",
    "    print(dsc, case_ids, slice_indices)\n",
    "    print(batch_idx)\n",
    "\n",
    "    if epoch == 0 and batch_idx == 1:\n",
    "        # Display CT slice and predicted segmentation\n",
    "        plt.imshow(X[4][0].cpu().numpy(), cmap='gray')\n",
    "        plt.title(\"CT Slice\")\n",
    "        plt.show()\n",
    "\n",
    "        pred_seg = X[4][1].cpu().numpy()\n",
    "        plt.imshow(pred_seg, cmap='gray')\n",
    "        plt.title(\"Predicted Segmentation\")\n",
    "        plt.show()\n",
    "\n",
    "        # Load and process ground truth\n",
    "        gt_path = dir / f\"labels-{case_ids[4]}.npy\"\n",
    "        gt_full = np.load(gt_path)  # shape [H, W, D]\n",
    "        gt = (gt_full[:, :, slice_indices[4]] == target_class).astype(np.uint8)\n",
    "\n",
    "        # Resize to match prediction size if needed\n",
    "        gt_tensor = torch.tensor(gt).unsqueeze(0).float()\n",
    "        gt_resized = TF.resize(gt_tensor, (256, 256)).squeeze().numpy().astype(np.uint8)\n",
    "\n",
    "        plt.imshow(gt_resized, cmap='gray')\n",
    "        plt.title(\"Ground Truth Segmentation\")\n",
    "        plt.show()\n",
    "\n",
    "        print(\"DSC:\", dsc[4])\n",
    "        # Compute MVSF\n",
    "        mv_score = mvsf(pred_seg, gt_resized)\n",
    "        print(\"MVSF:\", mv_score)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ad85976-d602-4169-81fc-9b4cf95110eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 1553980, 1554005, 1554029, 1554053, 1554077, 1554101, 1554125, 1554149) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[0;32m~/myenvv3.11.7/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "File \u001b[0;32m/appl/python/3.11.7/lib/python3.11/multiprocessing/queues.py:114\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll(timeout):\n\u001b[0;32m--> 114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "\u001b[0;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():  \u001b[38;5;66;03m# Disable grad tracking\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (X, dsc, case_ids, slice_indices) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;28mprint\u001b[39m(dsc, case_ids, slice_indices)\n\u001b[1;32m      9\u001b[0m         X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/myenvv3.11.7/lib/python3.11/site-packages/torch/utils/data/dataloader.py:435\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_iterator()\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 435\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/myenvv3.11.7/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1111\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._reset\u001b[0;34m(self, loader, first_iter)\u001b[0m\n\u001b[1;32m   1109\u001b[0m resume_iteration_cnt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_workers\n\u001b[1;32m   1110\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m resume_iteration_cnt \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1111\u001b[0m     return_idx, return_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(return_idx, _utils\u001b[38;5;241m.\u001b[39mworker\u001b[38;5;241m.\u001b[39m_ResumeIteration):\n\u001b[1;32m   1113\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m return_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/myenvv3.11.7/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1294\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1290\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1293\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1294\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1295\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1296\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/myenvv3.11.7/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1145\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1144\u001b[0m     pids_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(w\u001b[38;5;241m.\u001b[39mpid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[0;32m-> 1145\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpids_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) exited unexpectedly\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue\u001b[38;5;241m.\u001b[39mEmpty):\n\u001b[1;32m   1147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 1553980, 1554005, 1554029, 1554053, 1554077, 1554101, 1554125, 1554149) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set eval mode once\n",
    "target_class =4\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():  # Disable grad tracking\n",
    "        for batch_idx, (X, dsc, case_ids, slice_indices) in enumerate(test_loader):\n",
    "            print(dsc, case_ids, slice_indices)\n",
    "            X = X.to(device)\n",
    "            dsc = dsc.to(device)\n",
    "            \n",
    "            outputs = model(X)\n",
    "            pred_dsc = torch.sigmoid(outputs).squeeze()\n",
    "            print(pred_dsc)\n",
    "            print(dsc)\n",
    "\n",
    "            loss = maeLoss(pred_dsc, dsc)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Optional: plot only first batch of first epoch\n",
    "            if epoch == 0 and batch_idx == 0:\n",
    "                print(X[4][1].cpu().shape)\n",
    "                plt.imshow(X[4][0].cpu().numpy(), cmap='gray')\n",
    "                plt.title(\"CT Slice\")\n",
    "                plt.show()\n",
    "                plt.imshow(X[4][1].cpu().numpy(), cmap='gray')\n",
    "                plt.title(\"Predicted Segmentation\")\n",
    "                plt.show()\n",
    "                gt_path = dir / f\"labels-{case_ids[4]}.npy\"\n",
    "                gt = (np.load(gt_path)[:, :, slice_indices[4]] == target_class).astype(np.uint8)  # shape: [H, W]\n",
    "                gt_tensor = torch.tensor(gt).unsqueeze(0).float()  # shape [1, H, W]\n",
    "                gt_resized = TF.resize(gt_tensor, (256, 256))\n",
    "                plt.imshow(gt, cmap='gray')\n",
    "                plt.show()\n",
    "                print(dsc[4])\n",
    "                print(1- diceLoss(X[4][1].cpu().unsqueeze(0),gt_resized))\n",
    "        break\n",
    "    avg_loss = running_loss / len(test_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Test Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3a142aef-cc64-48c1-8fdc-e0c93b43d18f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fec006ce510>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[0][1].detach().cpu().numpy(),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcab249d-1d93-4b20-a4b1-384100ec3a82",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../predictions/qcKidneyDsc0.5Continued/results.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m qcData \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../predictions/qcKidneyDsc0.5Continued/results.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m case_number \u001b[38;5;241m=\u001b[39m qcData\u001b[38;5;241m.\u001b[39mcase\n\u001b[1;32m      3\u001b[0m slice_idx \u001b[38;5;241m=\u001b[39m qcData\u001b[38;5;241m.\u001b[39mslice\n",
      "File \u001b[0;32m~/myenvv3.11.7/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenvv3.11.7/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/myenvv3.11.7/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenvv3.11.7/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/myenvv3.11.7/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../predictions/qcKidneyDsc0.5Continued/results.csv'"
     ]
    }
   ],
   "source": [
    "qcData = pd.read_csv(\"../predictions\")\n",
    "case_number = qcData.case\n",
    "slice_idx = qcData.slice\n",
    "dsc = qcData.dsc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a2fd9a4e-492a-4776-ae9d-94dfd63376e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "qcData = pd.read_csv(\"predictions/qcKidneyDsc1.0/results.csv\")\n",
    "case_number = qcData.case\n",
    "slice_idx = qcData.slice\n",
    "dsc = qcData.dsc\n",
    "n = 0\n",
    "segPath = Path(f\"predictions/qcKidneyDsc1.0/{case_number[n]}_slice_{slice_idx[n]}_pred.npy\")\n",
    "seg = np.load(segPath)\n",
    "ctPath = dir / f\"volume-{case_number[n]}.npy\"\n",
    "ct = np.load(ctPath)[:,:,slice_idx[n]]\n",
    "\n",
    "# Resize CT slice\n",
    "ct = Image.fromarray(ct).convert(\"F\")\n",
    "ct = TF.resize(ct, (256,256))\n",
    "ct = np.array(ct, dtype=np.float32)\n",
    "\n",
    "X = np.stack([ct, seg], axis=0).astype(np.float32)\n",
    "X = torch.tensor(X).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c45fd11b-e1a5-4f7d-986b-91d3d40eb95f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = 0.7848139405250549\n",
      "Epoch 1: Loss = 0.7620207071304321\n",
      "Epoch 2: Loss = 0.7377638816833496\n",
      "Epoch 3: Loss = 0.7120381593704224\n",
      "Epoch 4: Loss = 0.6834508180618286\n",
      "Epoch 5: Loss = 0.6505779027938843\n",
      "Epoch 6: Loss = 0.6126081943511963\n",
      "Epoch 7: Loss = 0.5697599649429321\n",
      "Epoch 8: Loss = 0.5228103399276733\n",
      "Epoch 9: Loss = 0.4726947247982025\n",
      "Epoch 10: Loss = 0.42047998309135437\n",
      "Epoch 11: Loss = 0.36743050813674927\n",
      "Epoch 12: Loss = 0.31496506929397583\n",
      "Epoch 13: Loss = 0.2642830014228821\n",
      "Epoch 14: Loss = 0.21670913696289062\n",
      "Epoch 15: Loss = 0.1729605793952942\n",
      "Epoch 16: Loss = 0.13353604078292847\n",
      "Epoch 17: Loss = 0.09863024950027466\n",
      "Epoch 18: Loss = 0.06813013553619385\n",
      "Epoch 19: Loss = 0.041635096073150635\n",
      "Epoch 20: Loss = 0.018715381622314453\n",
      "Epoch 21: Loss = 0.004567980766296387\n",
      "Epoch 22: Loss = 0.008183836936950684\n",
      "Epoch 23: Loss = 0.01734262704849243\n",
      "Epoch 24: Loss = 0.023823559284210205\n",
      "Epoch 25: Loss = 0.028214573860168457\n",
      "Epoch 26: Loss = 0.030893981456756592\n",
      "Epoch 27: Loss = 0.03211104869842529\n",
      "Epoch 28: Loss = 0.032014429569244385\n",
      "Epoch 29: Loss = 0.030663490295410156\n",
      "Epoch 30: Loss = 0.028033733367919922\n",
      "Epoch 31: Loss = 0.024011611938476562\n",
      "Epoch 32: Loss = 0.018385767936706543\n",
      "Epoch 33: Loss = 0.010844290256500244\n",
      "Epoch 34: Loss = 0.0009348392486572266\n",
      "Epoch 35: Loss = 0.012082457542419434\n",
      "Epoch 36: Loss = 0.020063579082489014\n",
      "Epoch 37: Loss = 0.02257639169692993\n",
      "Epoch 38: Loss = 0.020433008670806885\n",
      "Epoch 39: Loss = 0.015064716339111328\n",
      "Epoch 40: Loss = 0.007942140102386475\n",
      "Epoch 41: Loss = 0.002362668514251709\n",
      "Epoch 42: Loss = 0.00348585844039917\n",
      "Epoch 43: Loss = 0.00696253776550293\n",
      "Epoch 44: Loss = 0.008707582950592041\n",
      "Epoch 45: Loss = 0.009082555770874023\n",
      "Epoch 46: Loss = 0.008314430713653564\n",
      "Epoch 47: Loss = 0.0065424442291259766\n",
      "Epoch 48: Loss = 0.0038371682167053223\n",
      "Epoch 49: Loss = 0.00022798776626586914\n",
      "Epoch 50: Loss = 0.004295229911804199\n",
      "Epoch 51: Loss = 0.007160663604736328\n",
      "Epoch 52: Loss = 0.008407533168792725\n",
      "Epoch 53: Loss = 0.008179962635040283\n",
      "Epoch 54: Loss = 0.006692826747894287\n",
      "Epoch 55: Loss = 0.004193782806396484\n",
      "Epoch 56: Loss = 0.0009207725524902344\n",
      "Epoch 57: Loss = 0.0029282569885253906\n",
      "Epoch 58: Loss = 0.00524294376373291\n",
      "Epoch 59: Loss = 0.0063024163246154785\n",
      "Epoch 60: Loss = 0.006291508674621582\n",
      "Epoch 61: Loss = 0.0056212544441223145\n",
      "Epoch 62: Loss = 0.004351198673248291\n",
      "Epoch 63: Loss = 0.002522587776184082\n",
      "Epoch 64: Loss = 0.00015991926193237305\n",
      "Epoch 65: Loss = 0.0027267932891845703\n",
      "Epoch 66: Loss = 0.004607856273651123\n",
      "Epoch 67: Loss = 0.005533099174499512\n",
      "Epoch 68: Loss = 0.005576908588409424\n",
      "Epoch 69: Loss = 0.004839658737182617\n",
      "Epoch 70: Loss = 0.003440380096435547\n",
      "Epoch 71: Loss = 0.0014944672584533691\n",
      "Epoch 72: Loss = 0.0008946061134338379\n",
      "Epoch 73: Loss = 0.0023301243782043457\n",
      "Epoch 74: Loss = 0.002950429916381836\n",
      "Epoch 75: Loss = 0.0028563737869262695\n",
      "Epoch 76: Loss = 0.0021241307258605957\n",
      "Epoch 77: Loss = 0.0008136630058288574\n",
      "Epoch 78: Loss = 0.0010335445404052734\n",
      "Epoch 79: Loss = 0.002035677433013916\n"
     ]
    }
   ],
   "source": [
    "model = QCUNet()\n",
    "\n",
    "def init_he(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "\n",
    "model.apply(init_he)\n",
    "model = model.to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(opt, step_size=20, gamma=0.7)\n",
    "\n",
    "model.train()\n",
    "num_epochs = 80\n",
    "\n",
    "X = X.to(device)\n",
    "dsc_tensor = torch.tensor([dsc[n]], dtype=torch.float32, device=device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    opt.zero_grad()\n",
    "    outputs = model(X)\n",
    "    predDSC = torch.sigmoid(outputs)\n",
    "    loss = maeLoss(predDSC, dsc_tensor)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    scheduler.step()\n",
    "    print(f\"Epoch {epoch}: Loss = {loss.item()}\")\n",
    "\n",
    "# Save model after training\n",
    "torch.save(model.state_dict(), \"qc_unet_overfit.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ca6a2138-62f4-4e66-b5b7-e233222c9153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted DSC: 0.827775239944458\n",
      "True DSC: 0.84209\n",
      "MAE: 0.014314770698547363\n"
     ]
    }
   ],
   "source": [
    "# Load the same model architecture\n",
    "model = QCUNet()\n",
    "model.load_state_dict(torch.load(\"qc_unet_overfit.pth\"))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    X = X.to(device)\n",
    "    output = model(X)\n",
    "    predDSC = torch.sigmoid(output)\n",
    "    true_dsc_tensor = torch.tensor([dsc[n]], dtype=torch.float32, device=device)\n",
    "    \n",
    "    print(\"Predicted DSC:\", predDSC.item())\n",
    "    print(\"True DSC:\", dsc[n])\n",
    "    print(\"MAE:\", maeLoss(predDSC, true_dsc_tensor).item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4e319721-6c4f-43ca-ad35-dd417fe43d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0294, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0262, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0147, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0064, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0060, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0071, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(5.2094e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0052, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0051, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(9.2387e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(9.5129e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(9.4771e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(8.4460e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(7.5758e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(7.8082e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(9.0837e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(3.8505e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(2.2471e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(7.2241e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.9431e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(5.5730e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(2.0504e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(9.0301e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(2.3842e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(3.2187e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(9.2030e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(4.8578e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(8.7440e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(4.5300e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(5.8174e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(3.9279e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(8.9288e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(5.0008e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(6.6221e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(2.8372e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(4.3511e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(6.3837e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(7.6771e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(9.5487e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(9.3579e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(2.7180e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(3.3498e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1444e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(8.5175e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(9.5308e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(2.7597e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.5318e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(3.5763e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(4.1604e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(2.4796e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(4.4286e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(5.2512e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(5.9009e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(9.0003e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(9.7513e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(2.1160e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(9.7752e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(7.9274e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(4.8876e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(3.1590e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(3.8147e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(4.6790e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(2.9802e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(9.5725e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(4.6849e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(3.9637e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(7.9393e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(7.7248e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(3.7134e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(3.6955e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(6.5565e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(5.3406e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(4.2915e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(7.8082e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(6.4909e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2279e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(4.3571e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(3.3677e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3411e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.7524e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(6.4373e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4901e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(2.9802e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(3.1233e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(5.7817e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(4.3929e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(6.1929e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(5.1379e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.5020e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(4.4405e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(7.1108e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(6.8367e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(3.9041e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4126e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(3.5226e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(2.7359e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(6.5565e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0133e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3471e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(7.8082e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4603e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.5914e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.7881e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1325e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.5020e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0669e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1981e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3471e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(3.9339e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(9.5367e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(2.0742e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(2.1279e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(2.9802e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(3.2246e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(4.5180e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(3.7909e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2577e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(2.9147e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(4.7803e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(4.5836e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(3.1352e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(5.0068e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(3.1888e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(5.1916e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(5.6565e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(4.7743e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(2.6405e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(5.9009e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(2.1756e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[105], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m     23\u001b[0m     opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 25\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m                      \n\u001b[1;32m     26\u001b[0m     predDSC \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(outputs)\n\u001b[1;32m     27\u001b[0m     loss \u001b[38;5;241m=\u001b[39m maeLoss(predDSC, dsc_tensor)\n",
      "File \u001b[0;32m~/myenvv3.11.7/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenvv3.11.7/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[24], line 81\u001b[0m, in \u001b[0;36mQCUNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     79\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdec5(x, x5)\n\u001b[1;32m     80\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdec4(x, x4)\n\u001b[0;32m---> 81\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdec3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx3\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdec2(x, x2)\n\u001b[1;32m     83\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdec1(x, x1)\n",
      "File \u001b[0;32m~/myenvv3.11.7/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenvv3.11.7/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[24], line 48\u001b[0m, in \u001b[0;36mDecoderBlock.forward\u001b[0;34m(self, x, skip)\u001b[0m\n\u001b[1;32m     46\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup(x)\n\u001b[1;32m     47\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((skip, x), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenvv3.11.7/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenvv3.11.7/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/myenvv3.11.7/lib/python3.11/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/myenvv3.11.7/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = QCUNet()\n",
    "\n",
    "# He initialization function\n",
    "def init_he(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "\n",
    "model.apply(init_he)\n",
    "model = model.to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(opt, step_size=20, gamma=0.7)\n",
    "\n",
    "model.train()\n",
    "num_epochs = 500\n",
    "\n",
    "X = X.to(device)\n",
    "dsc_tensor = torch.tensor([dsc[n]], dtype=torch.float32, device=device)\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    opt.zero_grad()\n",
    "\n",
    "    outputs = model(X)                      \n",
    "    predDSC = torch.sigmoid(outputs)\n",
    "    loss = maeLoss(predDSC, dsc_tensor)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ec93c81e-a1f4-459e-9d87-8e026bdbb22d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84209"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsc[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ce1310d2-3ab6-49b0-88d3-a5f713acfe4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8421], device='cuda:0')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsc_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b9d54f-0996-474f-9eeb-8d92dcbc54c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "model_name = os.path.splitext(os.path.basename(model_path))[0]\n",
    "save_dir = Path(\"predictions\") / model_name\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "results_csv = save_dir / \"results.csv\"\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (X, case_ids, slice_indices) in enumerate(allLoader):\n",
    "        inputs = X[:, 0:1, :, :].to(device)\n",
    "        labels = X[:, 1:, :, :].to(device)\n",
    "\n",
    "        outputs = torch.sigmoid(model(inputs))\n",
    "        preds_bin = (outputs > 0.5).float().cpu()\n",
    "\n",
    "        for i in range(inputs.shape[0]):\n",
    "            pred_mask = preds_bin[i, 0].numpy()\n",
    "            dsc_pred = 1 - diceLoss(preds_bin[i:i+1].to(device), labels[i:i+1]).item()\n",
    "            plt.imshow(labels[i:i+1].cpu().squeeze().squeeze())\n",
    "            case_id = case_ids[i].item()\n",
    "            slice_idx = int(slice_indices[i])\n",
    "            pred_filename = f\"{case_id}_slice_{slice_idx}_pred.npy\"\n",
    "            pred_path = save_dir / pred_filename\n",
    "            np.save(pred_path, pred_mask)\n",
    "\n",
    "            results.append({\n",
    "                \"case\": case_id,\n",
    "                \"slice\": slice_idx,\n",
    "                \"model\": model_name,\n",
    "                \"dsc\": round(dsc_pred, 5),\n",
    "                \"prediction_file\": pred_filename\n",
    "            })\n",
    "        if case_ids[0] > 2:\n",
    "            break\n",
    "\n",
    "# Save results CSV\n",
    "with open(results_csv, 'w', newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=[\"case\", \"slice\", \"model\", \"dsc\", \"prediction_file\"])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(results)\n",
    "\n",
    "print(f\"Saved predictions to {save_dir}\")\n",
    "print(f\"Saved CSV summary to {results_csv}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
